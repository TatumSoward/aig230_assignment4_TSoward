# AIG 230 – Lab 04  
## Word Embeddings: Learning Meaning from Context
THIS IS MY SUBMISSION FOR ASSIGNMENT 4. BELOW IS COPIED TEXT FROM THE INTIAL ASSIGNMENT README FROM DAVJES15'S TEMPLATE FOR POSTERITY PURPOSES. (I WANT TO KNOW WHAT THIS LAB IS ABOUT WHEN I LOOK AT THIS REPO IN A YEAR)
### Overview

This lab introduces **learned text representations**, commonly known as **word embeddings**.  
Unlike previous labs that relied on counting words or fixed n-gram contexts, this lab focuses on representations that are **learned from data**, **dense**, and **semantic**.

You will explore how models can learn meaning from word co-occurrence patterns and how these representations are used in practical NLP workflows.

---

### Learning Objectives

By completing this lab, you will be able to:

- Explain **distributional semantics** and why meaning can be learned from context
- Train word embeddings using **Word2Vec** and **FastText**
- Interpret **semantic similarity** using cosine distance
- Perform **vector algebra (analogies)** and explain why it works
- Visualize embedding spaces and reason about their structure
- Compare embeddings to n-gram and count-based representations
- Describe realistic **industry use cases** for word embeddings

---

### Topics Covered

This lab directly builds on the lecture material for Week 4 and covers:

- Learned representations vs engineered features  
- Distributional semantics (“a word is known by the company it keeps”)  
- Word2Vec (Skip-gram architecture, high-level intuition)  
- Semantic similarity and nearest neighbors  
- Vector arithmetic and analogies  
- Visualization of embedding spaces (PCA)  
- FastText and subword information  
- Conceptual comparison with GloVe  
- Practical limitations and evaluation considerations  


---

### Files in This Lab

- `AIG230_Week4_Lab_Word_Embeddings.ipynb`  
  The main lab notebook.  
  Includes:
  - Concept explanations
  - Fully commented code
  - Visualization
  - Multiple checkpoints for reflection and understanding
